#!/bin/bash -l
#SBATCH -C gpu
#SBATCH -t 00:20:00 
#SBATCH -J AMREX_GPU
#SBATCH -o AMREX_GPU.o%j
#SBATCH -A m2860

#SBATCH -N 1
#SBATCH -n 1
#SBATCH -c 10
#SBATCH --gres=gpu:1
#SBATCH --ntasks-per-node=1

# Note: Given exclusive configuration mode,
#       you MUST specify your desired resources up top like this.
#       Cannot put it in the srun line alone.
#       (You can force lower than your full request in the srun line,
#        or put the configuration again for safety, but shouldn't be needed.)
# ============
# -N =                nodes
# -n =                tasks (MPI ranks)
# -c =                CPU per task (full coriGPU node, c*n <= 80)
# --gres=gpu: =       GPUs per node (full coriGPU node, 8)
# --ntasks-per-node = number of tasks (MPI ranks) per node (full node, 8)
#

# For one node:  -N 1, -n  8, -c 10, --gres=gpu:8 --ntasks-per-node 8
# For two nodes: -N 2, -n 16, -c 10, --gres=gpu:8 --ntasks-per-node 8

# salloc commands:
# ================
# Single node:
# salloc -N 1 -t 2:00:00 -c 80 -C gpu --exclusive --gres=gpu:8 -A (your_repo)
# Multi node:
# salloc -N 2 -t 2:00:00 -c 80 -C gpu --exclusive --gres=gpu:8 -A (your_repo)

# environment setup:
# ==================
# module purge
# module load modules esslurm gcc cuda mvapich2 

EXE=./main3d.gnu.TPROF.CUDA.ex

# srun nvprof --print-gpu-trace --profile-child-processes ${EXE} ncell=256 max_grid_size=256 >& run-test.ou2

srun ${EXE} ncell=512 max_grid_size=512 >& run-512-512.ou
srun ${EXE} ncell=512 max_grid_size=256 >& run-512-256.ou
srun ${EXE} ncell=512 max_grid_size=128 >& run-512-128.ou
srun ${EXE} ncell=512 max_grid_size=64  >& run-512-64.ou
srun ${EXE} ncell=512 max_grid_size=32  >& run-512-32.ou
srun ${EXE} ncell=512 max_grid_size=16  >& run-512-16.ou
srun ${EXE} ncell=512 max_grid_size=8   >& run-512-8.ou

srun ${EXE} ncell=256 max_grid_size=256 >& run-256-256.ou
srun ${EXE} ncell=256 max_grid_size=128 >& run-256-128.ou
srun ${EXE} ncell=256 max_grid_size=64  >& run-256-64.ou
srun ${EXE} ncell=256 max_grid_size=32  >& run-256-32.ou
srun ${EXE} ncell=256 max_grid_size=16  >& run-256-16.ou
srun ${EXE} ncell=256 max_grid_size=8   >& run-256-8.ou

srun ${EXE} ncell=128 max_grid_size=128 >& run-128-128.ou
srun ${EXE} ncell=128 max_grid_size=64  >& run-128-64.ou
srun ${EXE} ncell=128 max_grid_size=32  >& run-128-32.ou
srun ${EXE} ncell=128 max_grid_size=16  >& run-128-16.ou
srun ${EXE} ncell=128 max_grid_size=8   >& run-128-8.ou

srun ${EXE} ncell=64 max_grid_size=64  >& run-64-64.ou
srun ${EXE} ncell=64 max_grid_size=32  >& run-64-32.ou
srun ${EXE} ncell=64 max_grid_size=16  >& run-64-16.ou
srun ${EXE} ncell=64 max_grid_size=8   >& run-64-8.ou

srun ${EXE} ncell=32 max_grid_size=32  >& run-32-32.ou
srun ${EXE} ncell=32 max_grid_size=16  >& run-32-16.ou
srun ${EXE} ncell=32 max_grid_size=8   >& run-32-8.ou

srun ${EXE} ncell=16 max_grid_size=16  >& run-16-16.ou
srun ${EXE} ncell=16 max_grid_size=8   >& run-16-8.ou

srun ${EXE} ncell=8 max_grid_size=8   >& run-8-8.ou
